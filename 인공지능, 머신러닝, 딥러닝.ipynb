{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 인공지능 ⊃ 머신러닝 ⊃ 딥러닝\n",
    "\n",
    "## 인공지능\n",
    "\n",
    "- 기계를 마치 사람처럼 지능적으로 만듦\n",
    "- 기계는 어떤 문제를 해결할 때 알고리즘에 기반을 함\n",
    "- 인공지능은 문제를 해결하는 알고리즘 규칙이 생성되는 과정에서 자체 규칙 시스템을 구축\n",
    "- 인공지능이 스스로 문제를 해결 할 수 있음\n",
    "\n",
    "## 머신러닝\n",
    "\n",
    "- 자체 규칙을 만들기 위해 제공된 데이터를 분석 후 학습\n",
    "- 학습을 받는 데이터가 많을수록 성능이 올라가기 때문에 빅데이터 요구\n",
    "- 학습을 바탕으로 어떤 문제에 대한 판단 혹은 예측\n",
    "\n",
    "## 딥러닝\n",
    "\n",
    "- 인간의 뇌의 뉴런과 유사한 정보 입출력 계층을 활용해 데이터를 학습\n",
    "- 데이터를 스스로 학습할 수 있음\n",
    "- 현재는 컴퓨터의 성능에 따라 학습되는 양, 속도의 차이가 크게 나고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 머신러닝\n",
    "\n",
    "\n",
    "1. supervised learning(지도학습)\n",
    "\n",
    "    - 1) classification(분류)\n",
    "        - identity fraud detection\n",
    "        - image classification\n",
    "        - customer retention\n",
    "        - diagnostics\n",
    "        \n",
    "    - 2) regression(회귀)\n",
    "        - population growth prediction\n",
    "        - estimating life expectancy\n",
    "        - market forecasting\n",
    "        - weather forecasting\n",
    "        - advertising popularity prediction\n",
    "\n",
    "\n",
    "2. unsupervised learning(비지도학습)\n",
    "\n",
    "    - 1) clustering(군집)\n",
    "        - recommender systems\n",
    "        - targetted marketing\n",
    "        - customer segmentation\n",
    "        \n",
    "    - 2) dimensionality reduction(차원축소)\n",
    "        - big data visualization\n",
    "        - meaningful compression\n",
    "        - structure discovery\n",
    "        - feature elicitation\n",
    "   \n",
    "   \n",
    "3. reinforcement learning(강화학습)\n",
    "\n",
    "    - real-time decisions\n",
    "    - robot navigation\n",
    "    - learning tasks\n",
    "    - skill acquisition\n",
    "    - game AI\n",
    "\n",
    "\n",
    "- 지도학습과 비지도학습의 가장 큰 차이 = 타겟값(y)의 유무\n",
    "- 타겟값 = 머신러닝이 학습 후 예측 혹은 분류해야 할 값\n",
    "- 비지도학습은 전체데이터를 가지고 이루어지는 반면\n",
    "- 지도학습은 학습데이터와 테스트데이터를 가지고 이루어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 공분산 & 상관계수\n",
    "\n",
    "- 양의 상관관계: 변수 x가 증가할 때 y도 증가\n",
    "- 음의 상관관계: 변수 x가 증가할 때 y는 감소\n",
    "- 상관관계 없음: 변수 x의 움직임과 y의 움직임이 상관 없음\n",
    "- 만약, x, y가 독립이면 공분산은 0\n",
    "- 단, 공분산은 x와 y의 크기에 영향을 받기 때문에 상관성은 낮지만 절대적 점수가 높은 공분산이 반대의 경우보다 높게 나올 수 있음\n",
    "- 상관계수는 공분산의 단점을 보완(-1 <= p <= 1)\n",
    "\n",
    "# 4. 상관관계와 인과관계\n",
    "\n",
    "- 상관관계는 두 변수 사이에서 보여지는 상관성만 나타낸 것\n",
    "- 인과관계란 x 때문에 y가 발생\n",
    "- 회귀분석을 통해 인과관계의 방향, 정도와 수학적 모델을 확인 가능\n",
    "\n",
    "# 5. 차원축소\n",
    "\n",
    "### 차원축소를 하는 이유\n",
    "\n",
    "- 사람이 보기에 시각적으로 용이함\n",
    "- 변수의 조합을 통해 새로운 변수 발견\n",
    "- 주의: 차원의 저주(차원, 즉 데이터 특징이 많아지면 이를 채우기 위한 데이터 수도 많아야 함/ 많지 않으면 오버피팅 문제)\n",
    "\n",
    "### feature selection(변수 선택)\n",
    "\n",
    "- 가지고 있는 변수들 중에 의미 있는 변수만 선택\n",
    "- 변수를 선택하는 방법은 주로 상관분석을 이용\n",
    "\n",
    "### feature extraction(변수 추출)\n",
    "\n",
    "- 변수 추출, 즉 1,2,3번 변수를 조합하여 A, B라는 변수를 생성\n",
    "- 주로 사용되는 방법은 주성분분석(PCA, Principal Component Analysis)\n",
    "- PCA 실행 결과 나온 variances를 그래프로 그린 뒤 급격하게 떨어지는 지점에서 PC개수 선택\n",
    "\n",
    "### PCA(Principal Component Analysis, 주성분분석)\n",
    "\n",
    "- 1. 분산이 최대인 축 찾기\n",
    "- 2. 찾은 축과 직교하면서 분산이 최대인 두 번째 축 찾기\n",
    "- 3. 첫번째 축과 두번째 축에 직교하고 분산을 보존하는 세번째 축 찾기\n",
    "\n",
    "### 정규화\n",
    "\n",
    "- PCA를 위해서는 반드시 정규화가 필요\n",
    "- 스케일이 다르면 분산이 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. clustering(군집화)\n",
    "\n",
    "## k-means\n",
    "\n",
    "- 주어진 값들 사이의 거리 혹은 유사성을 이용하여 분류\n",
    "- 전체 데이터를 k개의 집단으로 그룹화\n",
    "- 데이터를 기준점 중심으로 Euclidean거리가 최소가 되도록 k개의 그룹으로 군집\n",
    "- 군집별 중심 값에서 중심과의 거리를 기반으로 데이터를 분류하는 군집기법\n",
    "- 1. 초기 k개 군집의 중심 선택(랜덤)\n",
    "- 2. 값들의 거리를 비교 후 가까운 군집에 할당\n",
    "- 3. 새로운 군집의 중심 계산\n",
    "- 4. 재정의 된 중심값 기준으로 다시 거리기반의 군집 재분류, 경계가 변경되지 않으면 종료\n",
    "\n",
    "## k-means 특징\n",
    "\n",
    "- 거리를 이용한 분류(연속형O, 범주형X)\n",
    "- 반복된 작업 수행\n",
    "- 짧은 계산 시간\n",
    "- 주어진 자료에 대한 사전정보 없이 의미 있는 자료구조 찾기 가능\n",
    "- 범주형 변수를 다룰 경우 주의\n",
    "\n",
    "## k설정법\n",
    "\n",
    "- elbow point 찾기\n",
    "- k-means는 오브젝트와의 거리의 제곱합이 비용함수\n",
    "- k의 개수는 증가하지만 비용함수의 차이가 나지 않는 부분이 elbow point\n",
    "\n",
    "## k-means 결과 활용 방법\n",
    "\n",
    "1. 라벨 인코딩\n",
    "    - 머신러닝을 학습시키기 위해선 숫자가 아닌 단어 혹은 문자열을 숫자로 바꿔줘야만 학습이 가능\n",
    "    - 라벨 인코딩은 문자열을 카테고리별로 적용시키는 인코딩 방식\n",
    "\n",
    "\n",
    "2. 원핫인코딩\n",
    "    - 문자열을 숫자로 바꾼다는 점은 라벨 인코딩과 같지만 원핫인코딩은 문자열을 카테고리별로 바꾸는 것이 아닌 0과 1만 소유할 수 있는 테이블을 만들어 해당되는 데이터만 1로 표시하고 남은 데이터는 0으로 채우는 인코딩 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
