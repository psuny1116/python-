{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 탐색\n",
    "\n",
    "## 1) 데이터 불러오기, info, describe 확인, 결측치 확인\n",
    "```python\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head(2)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test.head(2)\n",
    "\n",
    "train.info()\n",
    "test.info()\n",
    "\n",
    "train.describe()\n",
    "test.describe()\n",
    "\n",
    "train.isna().sum() / len(train)\n",
    "test.isna().sum() / len(test)\n",
    "```\n",
    "\n",
    "## 2) 종속변수(타겟변수) 확인\n",
    "```python\n",
    "train['종속변수명'].value_counts()\n",
    "```\n",
    "\n",
    "## 3) 숫자형 변수와 범주형 변수 분리\n",
    "```python\n",
    "numeric_list = []\n",
    "categorical_list = []\n",
    "\n",
    "for i in train.columns:\n",
    "    if train[i].dtypes == 'O':\n",
    "        categorical_list.append(i)\n",
    "    else:\n",
    "        numeric_list.append(i)\n",
    "       \n",
    "# 종속변수가 들어있는 리스트에서 종속변수 제거\n",
    "종속변수들어간리스트_list.remove('종속변수 컬럼명')\n",
    "\n",
    "# 숫자형 변수와 종속변수의 상관성 확인\n",
    "for i in numeric_list:\n",
    "    answer = train[[i, '종속변수 컬럼명']].corr()\n",
    "    print(answer)\n",
    "    print()\n",
    "```\n",
    "\n",
    "## 4) 독립변수와 종속변수의 관계 확인\n",
    "```python\n",
    "train.columns\n",
    "print(train.groupby(['독립변수 컬럼명'])['종속변수 컬럼명'].mean())     # 분류문제 = mean(), 예측문제 = sum()\n",
    "```\n",
    "\n",
    "## 5) 컬럼의 nunique, unique 확인\n",
    "```python\n",
    "column_list = train.columns\n",
    "\n",
    "for i in column_list:\n",
    "    answer = train[i].nunique()\n",
    "    print(i, answer)\n",
    "    \n",
    "for i in column_list:\n",
    "    answer = train[i].unique()\n",
    "    print(i, answer)\n",
    "```\n",
    "\n",
    "## 6) 컬럼별 시각화\n",
    "```python\n",
    "# 분포 확인 시각화\n",
    "num_list = ['분포 확인할 컬럼명']\n",
    "\n",
    "for i in num_list:\n",
    "    sns.displot(train[i])\n",
    "    \n",
    "# 범주별 종속변수 시각화\n",
    "cat_list = ['범주형 컬럼명']\n",
    "\n",
    "for i in cat_list:\n",
    "    sns.catplot(data = train, x = i, hue = '종속변수 컬럼명', kind = 'count')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 전처리\n",
    "\n",
    "## 1) datetime(날짜컬럼) 전처리\n",
    "```python\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "\n",
    "train['year'] = train['datetime'].dt.year\n",
    "train['month'] = train['datetime'].dt.month\n",
    "train['day'] = train['datetime'].dt.day\n",
    "train['hour'] = train['datetime'].dt.hour\n",
    "train['dayofweek'] = train['datetime'].dt.dayofweek\n",
    "\n",
    "print(train['추가한 컬럼명'].unique())\n",
    "print(train.groupby(['추가한 컬럼명'])['종속변수 컬럼명'].mean())     # 또는 sum()\n",
    "\n",
    "train = train.drop(columns = ['필요없는 컬럼명'])\n",
    "\n",
    "# 최종적으로 추가한 컬럼 테스트 데이터에도 동일하게 적용(train, test 컬럼 동일해야 함)\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "test['year'] = test['datetime'].dt.year\n",
    "test['month'] = test['datetime'].dt.month\n",
    "test['day'] = test['datetime'].dt.day\n",
    "test['hour'] = test['datetime'].dt.hour\n",
    "test['dayofweek'] = test['datetime'].dt.dayofweek\n",
    "```\n",
    "\n",
    "## 2) 불필요한 컬럼 삭제\n",
    "```python\n",
    "y = train['종속변수 컬럼명']\n",
    "train = train.drop(columns = ['삭제할 컬럼명'])\n",
    "\n",
    "submission_id = test['id']     # 필요없을 수도 있음\n",
    "test = test.drop(columns = ['삭제할 컬럼명'])\n",
    "```\n",
    "\n",
    "## 3) 결측치 처리\n",
    "```python\n",
    "train.isna().sum() / len(train)\n",
    "test.isna().sum() / len(test)\n",
    "\n",
    "# 처리방법1. 특정값으로 대체(median, mean, value_counts의 가장 많은 값)\n",
    "train['결측치 존재 컬럼명'] = train['결측치 존재 컬럼명'].fillna(대체할 값)\n",
    "test['결측치 존재 컬럼명'] = test['결측치 존재 컬럼명'].fillna(대체할 값)\n",
    "\n",
    "# 처리방법2. 결측치 있는 컬럼 삭제\n",
    "train = train.drop(columns = ['결측치 존재 컬럼명'])\n",
    "test = test.drop(columns = ['결측치 존재 컬럼명'])\n",
    "```\n",
    "\n",
    "## 4) 범주형 변수 인코딩\n",
    "```python\n",
    "# 처리방법1. one hot encoding\n",
    "train = pd.get_dummies(train, columns = ['범주형 컬럼명'], drop_first = True)\n",
    "test = pd.get_dummies(test, columns = ['범주형 컬럼명'], drop_first = True)\n",
    "\n",
    "# 처리방법2. Label encoding(회귀 관련 알고리즘에는 사용 어려움. 단, tree계열은 괜찮음)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_list = ['범주형 컬럼명']\n",
    "\n",
    "for i in le_list:\n",
    "    encoder = LabelEncoder()\n",
    "    train[i] = encoder.fit_transform(train[i])\n",
    "    test[i] = encoder.fit_transform(test[i])\n",
    "```\n",
    "\n",
    "## 5) 파생변수 추가\n",
    "- train, test 모두에 추가해야함. train, test 데이터의 컬럼 동일해야 함\n",
    "\n",
    "## 6) 표준화(스케일링)\n",
    "```python\n",
    "# 처리방법1. StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "\n",
    "# 처리방법2. MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns = test.columns)\n",
    "```\n",
    "\n",
    "## 7) 컬럼 간 상관관계 확인\n",
    "```python\n",
    "train[['컬럼명1', '컬럼명2', ...]].corr()\n",
    "\n",
    "# 0.6이상인 컬럼들이 있으면 둘 중 한 컬럼 삭제\n",
    "train = train.drop(columns = ['삭제할 컬럼명'])\n",
    "test = test.drop(columns = ['삭제할 컬럼명'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 학습 및 평가\n",
    "\n",
    "## 1) train 데이터를 학습용과 검증용으로 분할\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, y, test_size = 0.3, stratify = y, random_state = 2022)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "```\n",
    "\n",
    "## 2) 학습 - 분류(성별 분류, 생존 여부 분류 등)의 경우\n",
    "```python\n",
    "# 모델1: RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state = 2022, max_depth = 5, n_estimators = 200)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 모델2: XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(random_state = 2022, max_depth = 5, n_estimators = 200)\n",
    "model.fit(x_train, y_train)\n",
    "```\n",
    "\n",
    "## 2) 학습 - 예측(수요 예측 등)의 경우\n",
    "```python\n",
    "# 모델1: RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state = 2022, max_depth = 5, n_estimators = 200)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 모델2: XGBRegressor\n",
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(random_state = 2022, max_depth = 5, n_estimators = 200)\n",
    "model.fit(x_train, y_train)\n",
    "```\n",
    "\n",
    "## 3) 모델 성능 평가 - 분류의 경우\n",
    "```python\n",
    "y_test_predicted = pd.DataFrame(model.predict(x_test))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "print(roc_auc_score(y_test, y_test_predicted))\n",
    "print(accuracy_score(y_test, y_test_predicted))\n",
    "```\n",
    "\n",
    "## 3) 모델 성능 평가 - 예측의 경우\n",
    "```python\n",
    "y_test_predicted = pd.DataFrame(model.predict(x_test))\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "print(r2_score(y_test, y_test_predicted))\n",
    "print(mean_squared_error(y_test, y_test_predicted))     # MSE\n",
    "print(mean_squared_error(y_test, y_test_predicted, squared = False))     # RMSE\n",
    "print(mean_absolute_error(y_test, y_test_predicted))     # MAE\n",
    "```\n",
    "\n",
    "## 4) 하이퍼파라미터 조절\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators' : [100, 200, 300, 400, 500], 'max_depth' : [5, 7, 9, 11, 13]}\n",
    "\n",
    "model_hy = RandomForestClassifier(random_state = 2022)\n",
    "grid_cv = GridSearchCV(model_hy, param_grid = params, cv = 3, scoring = '모델 성능 평가 이름')\n",
    "# scoring 예: 'roc_auc', 'accuracy', 'r2', 'neg_mean_squared_error', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'\n",
    "grid_cv.fit(x_train, y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "```\n",
    "\n",
    "## 5) 모델 재학습 및 성능평가\n",
    "- 위에서 나온 최적 하이퍼 파라미터를 적용해 2) 학습 및 3) 모델 성능 평가 재수행\n",
    "\n",
    "## 6) 중요 변수 파악\n",
    "```python\n",
    "pd.Series(model.feature_importances_, index = x_train.columns).sort_values(ascending = False)\n",
    "```\n",
    "\n",
    "## 7) 최종 결과 예측\n",
    "```python\n",
    "# predict_proba: 분류에서 0인지 1인지가 아니라 0일 확률, 1일 확률을 구하는 경우\n",
    "result = pd.DataFrame(model.predict_proba(test))[0 또는 1]     # 0일 확률이면 0, 1일 확률이면 1\n",
    "\n",
    "# predict: 분류에서 0인지 1인지 구하는 경우 또는 예측 문제의 경우\n",
    "result = pd.DataFrame(model.predict(test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 결과 제출\n",
    "\n",
    "```python\n",
    "final = pd.concat([submission_id, result], axis = 1)     # 최종 데이터에 id컬럼 추가해야 한다면! 아니면 result만 출력\n",
    "final = final.rename(columns = {'변경 필요한 컬럼명' : '변경할 컬럼명'})\n",
    "final.to_csv('파일명.csv', index = False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
